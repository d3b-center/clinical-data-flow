{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from pprint import pprint, pformat\n",
    "\n",
    "from graph import Graph\n",
    "import pandas\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "pandas.options.display.max_colwidth = 0\n",
    "\n",
    "from kf_lib_data_ingest.common.io import (\n",
    "    read_df\n",
    ")\n",
    "from kf_lib_data_ingest.common.concept_schema import (\n",
    "    CONCEPT,\n",
    "    DELIMITER,\n",
    "    concept_from,\n",
    "    concept_attr_from\n",
    ")\n",
    "\n",
    "SOURCE_DATA_DIR = os.path.abspath('data')\n",
    "TEST_DATA_DIR = os.path.join(SOURCE_DATA_DIR, 'test')\n",
    "EXTRACT_DATA_DIR = os.path.join('./output/ExtractStage/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     1,
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted data files ....\n",
      "\n",
      "Test data files ....\n"
     ]
    }
   ],
   "source": [
    "def display_dfs(df_dict):\n",
    "    for key, df in df_dict.items():\n",
    "        print(f'Dataframe {key}')\n",
    "        display(df)\n",
    "        \n",
    "def load_data(input_dir, enable_display=False):\n",
    "    out_dfs = {}\n",
    "    for fn in os.listdir(input_dir):\n",
    "        fp = os.path.join(input_dir, fn)\n",
    "        ext = os.path.splitext(fn)[-1]\n",
    "        if (os.path.isfile(fp) and (not fn.startswith('.')) and (ext not in {'.zip', '.json'})):\n",
    "            out_dfs[fn] = read_df(os.path.join(input_dir, fn))\n",
    "    if enable_display:\n",
    "        print(f'Loading {fn} into df')\n",
    "        display_dfs(out_dfs)\n",
    "\n",
    "    return out_dfs\n",
    "\n",
    "# Read in source data files into dict\n",
    "# print('Source data files ....')\n",
    "# source_data_dfs = load_data(SOURCE_DATA_DIR)\n",
    "\n",
    "print('\\nExtracted data files ....')\n",
    "# Read in extracted data files into dict\n",
    "extract_data_dfs = load_data(EXTRACT_DATA_DIR)\n",
    "\n",
    "# Test dataframes\n",
    "print('\\nTest data files ....')\n",
    "test_data_dfs = load_data(TEST_DATA_DIR, enable_display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     6,
     15,
     16,
     22,
     55,
     99,
     106,
     154,
     160,
     195,
     219,
     253,
     296,
     313,
     326,
     429,
     460,
     482
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PARTICIPANT|ID-->FAMILY|ID test on 6 files ...\n",
      "Running FAMILY|ID-->PARTICIPANT|ID test on 6 files ...\n",
      "Running BIOSPECIMEN|ID-->PARTICIPANT|ID test on 6 files ...\n",
      "Running PARTICIPANT|ID-->BIOSPECIMEN|ID test on 6 files ...\n",
      "Running GENOMIC_FILE|URL_LIST-->BIOSPECIMEN|ID test on 6 files ...\n",
      "Running BIOSPECIMEN|ID-->GENOMIC_FILE|URL_LIST test on 6 files ...\n",
      "Running PARTICIPANT|ID-->PARTICIPANT|GENDER test on 6 files ...\n",
      "Running PARTICIPANT|ID-UNIQUE-COUNT test on 6 files ...\n",
      "Running BIOSPECIMEN|ID-UNIQUE-COUNT test on 6 files ...\n",
      "Index(['result', 'name', 'details'], dtype='object')\n",
      "\n",
      "Generated validation report at /Users/singhn4/Projects/kids_first/kf-ingest-packages/kf_ingest_packages/packages/SD_46SK55A3/validation_report.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>details</th>\n",
       "      <th>error_locations</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>☑️</td>\n",
       "      <td>A Participant must have exactly 1 gender</td>\n",
       "      <td>Every uniquely identifiable Participant must have exactly 1 gender from the acceptable list: Male, Female</td>\n",
       "      <td>Test did not run, required columns not found ('PARTICIPANT|ID', 'PARTICIPANT|GENDER')</td>\n",
       "      <td></td>\n",
       "      <td>attribute-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅</td>\n",
       "      <td>Expected Participant Unique Count = 10</td>\n",
       "      <td>The number of uniquely identifiable participants found in study must be equal to 10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>count-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅</td>\n",
       "      <td>Expected Specimen Unique Count = 12</td>\n",
       "      <td>The number of uniquely identifiable specimens found in study must be equal to 12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>count-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Participant is in at least 1 Family Group</td>\n",
       "      <td>Every uniquely identifiable Participant must be linked to at  least 1 uniquely identifiable Family within the study</td>\n",
       "      <td>Participant P11 is linked to 0 Family entities</td>\n",
       "      <td>Found P11 in files: {'pf.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Family Group must have at least 1 Participant</td>\n",
       "      <td>Every uniquely identifiable Family Group must have at least 1 uniquely identifiable Participant within the study</td>\n",
       "      <td>Family F12 is linked to 0 Participant entities</td>\n",
       "      <td>Found F12 in files: {'pf.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Specimen comes from 1 Participant</td>\n",
       "      <td>Every uniquely identifiable Specimen must be linked to  exactly 1 uniquely identifiable Participant within the study</td>\n",
       "      <td>Biospecimen S2 is linked to 2 Participant entities: {'P1', 'P2'}\\nBiospecimen S8 is linked to 0 Participant entities</td>\n",
       "      <td>Found S2 in files: {'spf.csv', 'sfp2.csv'}\\nFound S8 in files: {'spf.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Participant must have at least 1 Specimen</td>\n",
       "      <td>Every uniquely identifiable Participant must have at least 1  uniquely identifiable Specimen within the study</td>\n",
       "      <td>Participant P11 is linked to 0 Biospecimen entities\\nParticipant P13 is linked to 0 Biospecimen entities</td>\n",
       "      <td>Found P11 in files: {'pf.csv'}\\nFound P13 in files: {'pf.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Sequence Manifest File Record represents only 1 Specimen</td>\n",
       "      <td>Every uniquely identifiable Sequence Manifest File Record must be linked to exactly 1 uniquely identifiable Specimen within the study</td>\n",
       "      <td>Genomic_File ['foo/s11.txt'] is linked to 0 Biospecimen entities\\nGenomic_File ['foo/s5.txt'] is linked to 0 Biospecimen entities\\nGenomic_File ['foo/s9.txt'] is linked to 0 Biospecimen entities</td>\n",
       "      <td>Found ['foo/s11.txt'] in files: {'pg.csv'}\\nFound ['foo/s5.txt'] in files: {'pg.csv'}\\nFound ['foo/s9.txt'] in files: {'pg.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Specimen must have at least 1 Sequence Manifest File Record</td>\n",
       "      <td>Every uniquely identifiable specimen must be linked to at least 1 uniquely identifiable Sequence Manifest File Record within the study</td>\n",
       "      <td>Biospecimen NA is linked to 0 Genomic_File entities\\nBiospecimen S1 is linked to 0 Genomic_File entities\\nBiospecimen S11 is linked to 0 Genomic_File entities\\nBiospecimen S2 is linked to 0 Genomic_File entities\\nBiospecimen S3 is linked to 0 Genomic_File entities\\nBiospecimen S4 is linked to 0 Genomic_File entities\\nBiospecimen S5 is linked to 0 Genomic_File entities\\nBiospecimen S6 is linked to 0 Genomic_File entities\\nBiospecimen S8 is linked to 0 Genomic_File entities\\nBiospecimen S9 is linked to 0 Genomic_File entities</td>\n",
       "      <td>Found NA in files: {'sfp2.csv'}\\nFound S1 in files: {'spf.csv'}\\nFound S11 in files: {'sp.csv'}\\nFound S2 in files: {'spf.csv', 'sfp2.csv'}\\nFound S3 in files: {'spf.csv'}\\nFound S4 in files: {'spf.csv'}\\nFound S5 in files: {'spf.csv'}\\nFound S6 in files: {'spf.csv'}\\nFound S8 in files: {'spf.csv'}\\nFound S9 in files: {'spf.csv'}</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  result                                                           name  \\\n",
       "0  ☑️     A Participant must have exactly 1 gender                        \n",
       "0  ✅      Expected Participant Unique Count = 10                          \n",
       "0  ✅      Expected Specimen Unique Count = 12                             \n",
       "0  ❌      A Participant is in at least 1 Family Group                     \n",
       "0  ❌      A Family Group must have at least 1 Participant                 \n",
       "0  ❌      A Specimen comes from 1 Participant                             \n",
       "0  ❌      A Participant must have at least 1 Specimen                     \n",
       "0  ❌      A Sequence Manifest File Record represents only 1 Specimen      \n",
       "0  ❌      A Specimen must have at least 1 Sequence Manifest File Record   \n",
       "\n",
       "                                                                                                                              description  \\\n",
       "0  Every uniquely identifiable Participant must have exactly 1 gender from the acceptable list: Male, Female                                \n",
       "0  The number of uniquely identifiable participants found in study must be equal to 10                                                      \n",
       "0  The number of uniquely identifiable specimens found in study must be equal to 12                                                         \n",
       "0  Every uniquely identifiable Participant must be linked to at  least 1 uniquely identifiable Family within the study                      \n",
       "0  Every uniquely identifiable Family Group must have at least 1 uniquely identifiable Participant within the study                         \n",
       "0  Every uniquely identifiable Specimen must be linked to  exactly 1 uniquely identifiable Participant within the study                     \n",
       "0  Every uniquely identifiable Participant must have at least 1  uniquely identifiable Specimen within the study                            \n",
       "0  Every uniquely identifiable Sequence Manifest File Record must be linked to exactly 1 uniquely identifiable Specimen within the study    \n",
       "0  Every uniquely identifiable specimen must be linked to at least 1 uniquely identifiable Sequence Manifest File Record within the study   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             details  \\\n",
       "0  Test did not run, required columns not found ('PARTICIPANT|ID', 'PARTICIPANT|GENDER')                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "0  None                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "0  None                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "0  Participant P11 is linked to 0 Family entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "0  Family F12 is linked to 0 Participant entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "0  Biospecimen S2 is linked to 2 Participant entities: {'P1', 'P2'}\\nBiospecimen S8 is linked to 0 Participant entities                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "0  Participant P11 is linked to 0 Biospecimen entities\\nParticipant P13 is linked to 0 Biospecimen entities                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "0  Genomic_File ['foo/s11.txt'] is linked to 0 Biospecimen entities\\nGenomic_File ['foo/s5.txt'] is linked to 0 Biospecimen entities\\nGenomic_File ['foo/s9.txt'] is linked to 0 Biospecimen entities                                                                                                                                                                                                                                                                                                                                                  \n",
       "0  Biospecimen NA is linked to 0 Genomic_File entities\\nBiospecimen S1 is linked to 0 Genomic_File entities\\nBiospecimen S11 is linked to 0 Genomic_File entities\\nBiospecimen S2 is linked to 0 Genomic_File entities\\nBiospecimen S3 is linked to 0 Genomic_File entities\\nBiospecimen S4 is linked to 0 Genomic_File entities\\nBiospecimen S5 is linked to 0 Genomic_File entities\\nBiospecimen S6 is linked to 0 Genomic_File entities\\nBiospecimen S8 is linked to 0 Genomic_File entities\\nBiospecimen S9 is linked to 0 Genomic_File entities   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                               error_locations  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                \n",
       "0  None                                                                                                                                                                                                                                                                                                                                          \n",
       "0  None                                                                                                                                                                                                                                                                                                                                          \n",
       "0  Found P11 in files: {'pf.csv'}                                                                                                                                                                                                                                                                                                                \n",
       "0  Found F12 in files: {'pf.csv'}                                                                                                                                                                                                                                                                                                                \n",
       "0  Found S2 in files: {'spf.csv', 'sfp2.csv'}\\nFound S8 in files: {'spf.csv'}                                                                                                                                                                                                                                                                    \n",
       "0  Found P11 in files: {'pf.csv'}\\nFound P13 in files: {'pf.csv'}                                                                                                                                                                                                                                                                                \n",
       "0  Found ['foo/s11.txt'] in files: {'pg.csv'}\\nFound ['foo/s5.txt'] in files: {'pg.csv'}\\nFound ['foo/s9.txt'] in files: {'pg.csv'}                                                                                                                                                                                                              \n",
       "0  Found NA in files: {'sfp2.csv'}\\nFound S1 in files: {'spf.csv'}\\nFound S11 in files: {'sp.csv'}\\nFound S2 in files: {'spf.csv', 'sfp2.csv'}\\nFound S3 in files: {'spf.csv'}\\nFound S4 in files: {'spf.csv'}\\nFound S5 in files: {'spf.csv'}\\nFound S6 in files: {'spf.csv'}\\nFound S8 in files: {'spf.csv'}\\nFound S9 in files: {'spf.csv'}   \n",
       "\n",
       "           test_type  \n",
       "0  attribute-test     \n",
       "0  count-test         \n",
       "0  count-test         \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "# - Add enable/disable param for test params\n",
    "# - Add one custom test class and instance\n",
    "# - Add type safety to all classes\n",
    "# - Convert print statements to logging statements\n",
    "\n",
    "def result_to_emoji(result):\n",
    "    result = int(result)\n",
    "    emap = {\n",
    "        0: '❌',\n",
    "        1: '✅',\n",
    "        2: '☑️'\n",
    "    }\n",
    "    return emap[result]\n",
    "\n",
    "def validate_count(count, min_count, max_count):\n",
    "    if count < min_count:\n",
    "        return False\n",
    "    if (max_count is not None) and (count > max_count):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def stack_dfs(df_dict, left, right=None):\n",
    "    cumulative_df = None\n",
    "    for fn, df in df_dict.items():\n",
    "        # Strip whitespace from column names\n",
    "        df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "        # Select subset\n",
    "        if left not in df.columns:\n",
    "            continue\n",
    "        extract_cols = set([left, right]) & set(df.columns)\n",
    "        df = df[extract_cols]\n",
    "\n",
    "        # Re-order columns for debugging\n",
    "        if len(df.columns) > 1:\n",
    "            df = df[[left, right]]\n",
    "        \n",
    "        # Drop rows where value of left col is null    \n",
    "        df = df[(df[left] != '') & (df[left].notnull())]\n",
    "        \n",
    "        # Stack dfs\n",
    "        if cumulative_df is None:\n",
    "            cumulative_df = df\n",
    "\n",
    "        cumulative_df = pandas.concat([cumulative_df, df])\n",
    "    \n",
    "    # Drop duplicates\n",
    "    try:\n",
    "        cumulative_df.drop_duplicates(inplace=True)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    return cumulative_df\n",
    "\n",
    "def direct_connections(df_dict, left_col, right_col):\n",
    "    \"\"\"\n",
    "    Given an input pandas.DataFrame consisting of two columns, \n",
    "    left_col and right_col, produce a DataFrame that represents groups of \n",
    "    right_col values associated with each unique left_col value. \n",
    "    Then add another column that captures the number of unique items in a group.\n",
    "\n",
    "    This DataFrame represents a graph showing direct connections between\n",
    "    values of left_col and values of right_col.\n",
    "\n",
    "    Example output:\n",
    "        | PARTICIPANT.ID |    FAMILY.ID    | count |\n",
    "        |----------------|-----------------|-------|\n",
    "        |     P1         |    {F1, F2}     |   2   |\n",
    "        |     P2         |  {F1, F1, F2 }  |   2   |\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stack dfs     \n",
    "    df = stack_dfs(df_dict, left_col, right_col)\n",
    "    \n",
    "    # Create groups     \n",
    "    diff = set(df.columns) ^ set([left_col, right_col])\n",
    "    if (df is not None) and (not diff):\n",
    "        gdf = (\n",
    "            df.groupby([left_col])[right_col]\n",
    "            .apply(set)\n",
    "            .reset_index(name=right_col)\n",
    "        )\n",
    "        \n",
    "        def remove_nulls(linked_nodes):\n",
    "            return {\n",
    "                n for n in linked_nodes\n",
    "                if pandas.notnull(n) and n\n",
    "            }\n",
    "        gdf[right_col] = gdf[right_col].apply(lambda linked_nodes: remove_nulls(linked_nodes))\n",
    "        \n",
    "        gdf['linked_node_count'] = gdf[right_col].apply(\n",
    "            lambda linked_nodes: len(linked_nodes)\n",
    "        )\n",
    "    else:\n",
    "        gdf = None\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def file_locations(error_value, df_dict):\n",
    "    locs = set()\n",
    "    for fn, df in df_dict.items():\n",
    "        if any(df.isin([str(error_value)]).any(1).to_list()): \n",
    "            locs.add(fn)\n",
    "    return (error_value, locs)\n",
    "\n",
    "class ValidationTest(ABC):\n",
    "    def __init__(self, name, description, test_type, test_params, id=None):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.test_type = test_type\n",
    "        self.test_params = test_params\n",
    "    \n",
    "    def run(self, df_dict, *args, **kwargs):\n",
    "        print(f'Running {self.id} test on {len(df_dict.values())} files ...')\n",
    "        return self._run(df_dict, *args, **kwargs)\n",
    "        \n",
    "    def build_report(self, *args, **kwargs):\n",
    "        required_columns = set(['name', 'description', 'result', 'details'])\n",
    "\n",
    "        df = self._build_report(*args, **kwargs)\n",
    "        if not isinstance(df, pandas.DataFrame):\n",
    "            raise Exception(\n",
    "                f'{type(self).__name__}_build_report must return '\n",
    "                f'a pandas.DataFrame object!'\n",
    "            )\n",
    "\n",
    "        if not (required_columns.issubset(set(df.columns))):\n",
    "            raise Exception(\n",
    "                f'{type(self).__name__}_build_report DataFrame must have all required '\n",
    "                f'columns: {required_columns}'\n",
    "            )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _run(self, df_dict):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _build_report(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'test_id': self.id,\n",
    "            'type': self.test_type,\n",
    "            'name': self.name,\n",
    "            'description': self.description,\n",
    "            'input_params': self.test_params\n",
    "        }\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        return pandas.DataFrame([self.to_dict()])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return pformat(self.to_dict())\n",
    "\n",
    "class ValidationTestResult(ABC):\n",
    "    def __init__(self, validation_test, result, data, message=None, result_details=None, error_locations=None):\n",
    "        self.id = None\n",
    "        self.validation_test = validation_test\n",
    "        self.result = result\n",
    "        self.data = data\n",
    "        self.message = message or (\n",
    "            f\"{result_to_emoji(int(result))} \"\n",
    "            f\"{self.validation_test.test_type.title()} \"\n",
    "            f\"for '{self.validation_test.name}' \"\n",
    "            f\"{'Succeeded!' if result else 'Failed!'}\"\n",
    "        )\n",
    "        self.result_details = result_details\n",
    "        self.error_locations = error_locations\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = self.validation_test.to_dict()\n",
    "        d.update({\n",
    "            'result': self.result,\n",
    "            'data': self.data,\n",
    "            'message': self.message,\n",
    "            'details': self.result_details,\n",
    "            'error_locations': self.error_locations\n",
    "        })\n",
    "        return d\n",
    "    \n",
    "    def to_dataframe(self):\n",
    "        d = self.to_dict()\n",
    "        df = pandas.DataFrame([d])\n",
    "        return df.drop('data', axis=1)\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pformat(self.to_dict())\n",
    "        \n",
    "class CountValidationTest(ValidationTest):\n",
    "    def __init__(self, name, description, concept_name, min_count, max_count):\n",
    "        super().__init__(\n",
    "            name,\n",
    "            description,\n",
    "            id=f'{concept_name}-UNIQUE-COUNT', \n",
    "            test_type='count-test',\n",
    "            test_params=(concept_name, min_count, max_count)\n",
    "        )\n",
    "        self.concept_name = concept_name\n",
    "        self.min_count = min_count\n",
    "        self.max_count = max_count\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = super().to_dict()\n",
    "        d.update(\n",
    "            {\n",
    "                'concept': self.concept_name,\n",
    "                'min_count': self.min_count,\n",
    "                'max_count': self.max_count\n",
    "            }\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "    def _run(self, df_dict):\n",
    "        # Stack dfs vertically into 1 df         \n",
    "        cumulative_df = stack_dfs(\n",
    "            df_dict,\n",
    "            self.concept_name\n",
    "        )\n",
    "        if (cumulative_df is None) or (cumulative_df.empty):\n",
    "            return ValidationTestResult(\n",
    "                self, 2, None, \n",
    "                result_details=(\n",
    "                    'Test did not run due to missing required columns: '\n",
    "                    f'{self.concept_name}'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # Unique count test\n",
    "            error = None\n",
    "            uc = cumulative_df.nunique().values[0]\n",
    "            result = validate_count(uc, self.min_count, self.max_count)\n",
    "            # Count check failed\n",
    "            if not result:\n",
    "                error = (self.concept_name, uc) \n",
    "            return ValidationTestResult(self, result, None, result_details=error)\n",
    "\n",
    "    def _build_report(self, test_df):\n",
    "        report_df = test_df[['result', 'name', 'description', 'details', 'error_locations']]\n",
    "        report_df['result'] = test_df['result'].apply(\n",
    "            lambda x: result_to_emoji(x)\n",
    "        )\n",
    "        report_df['details'] = test_df['details'].apply(\n",
    "            lambda x: f'Found {x[1]} {x[0]} in data' if x else None\n",
    "        )\n",
    "        return report_df\n",
    "\n",
    "class EntityTypeGraph(object):\n",
    "    def __init__(self, relations):\n",
    "        self.adj_list = relations\n",
    "        self.graph = self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        graph = Graph()\n",
    "        for node, neighbors in self.adj_list.items():\n",
    "            if node not in graph:\n",
    "                graph.add_node(node)\n",
    "            # Add directed edge from node to neighbor\n",
    "            for n in neighbors:\n",
    "                # Add neighbor node if not in graph\n",
    "                if n not in graph:\n",
    "                    graph.add_node(n)\n",
    "                graph.add_edge(node, n)\n",
    "        return graph\n",
    "    \n",
    "    def ancestors(self, node_id):\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            a = self.graph.nodes(to_node=node_id)\n",
    "            if a:\n",
    "                ancestors.extend(a)\n",
    "                node_id = a[0]\n",
    "            else:\n",
    "                break\n",
    "        return ancestors\n",
    "\n",
    "    def descendants(self, node_id):\n",
    "        descendants = []\n",
    "        while True:\n",
    "            d = self.graph.nodes(from_node=node_id)\n",
    "            if d:\n",
    "                descendants.extend(d)\n",
    "                node_id = d[0]\n",
    "            else:\n",
    "                break\n",
    "        return descendants\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pformat(self._adj_list)\n",
    "      \n",
    "class RelationshipValidationTest(ValidationTest):\n",
    "    \"\"\"\n",
    "    Validate relationships between enitity instances\n",
    "\n",
    "    For example given:\n",
    "    \n",
    "        self.node_left=SPECIMEN.ID\n",
    "        self.node_right=PARTICIPANT.ID\n",
    "        self.min_relations=1\n",
    "        self.max_relations =1\n",
    "\n",
    "    A SPECIMEN must be linked to at least 1 PARTICIPANT and no more than 1 PARTICIPANT\n",
    "    Find the SPECIMENS that violate this rule\n",
    "    \"\"\"  \n",
    "    def __init__(\n",
    "        self, name, description, node_left, node_right, min_relations, max_relations, type_relations=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name,\n",
    "            description,\n",
    "            id=f'{node_left}-->{node_right}', \n",
    "            test_type='relationship-test',\n",
    "            test_params=(node_left, node_right, min_relations, max_relations)\n",
    "        )\n",
    "        self.node_left = node_left\n",
    "        self.node_right = node_right\n",
    "        self.min_relations = min_relations\n",
    "        self.max_relations = max_relations\n",
    "        self.relations = type_relations\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = super().to_dict()\n",
    "        d.update(\n",
    "            {'relation': (self.node_left, self.node_right)}\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "    def _run(self, df_dict):\n",
    "        # For every instance of node_left, get group of connected node_right\n",
    "        df = direct_connections(df_dict, self.node_left, self.node_right)\n",
    "            \n",
    "        # Test did not run if neither node exists\n",
    "        if (df is None) or (df.empty):\n",
    "            return ValidationTestResult(\n",
    "                self, 2, None, \n",
    "                result_details=(\n",
    "                    f'Test did not run, required columns not found {self.node_left, self.node_right}'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Test failed if 0 links were found         \n",
    "        if len(df.columns) == 1:\n",
    "            return ValidationTestResult(self, False, None)\n",
    "        \n",
    "        # Validate relationships in cumulative data          \n",
    "        else:\n",
    "            invalid_rows = df[~df['linked_node_count'].apply(\n",
    "                lambda c: validate_count(c, self.min_relations, self.max_relations)\n",
    "            )]\n",
    "            errors = [\n",
    "                (row[self.node_left], row[self.node_right])\n",
    "                for i, row in invalid_rows.iterrows()\n",
    "            ]\n",
    "            \n",
    "            #  Collect file locations of error values\n",
    "            file_locations_per_error = [\n",
    "                file_locations(node, df_dict)\n",
    "                for node, _ in errors\n",
    "            ]\n",
    "            \n",
    "            return ValidationTestResult(\n",
    "                self, \n",
    "                invalid_rows.empty, \n",
    "                invalid_rows, \n",
    "                result_details=errors, \n",
    "                error_locations=file_locations_per_error\n",
    "            )\n",
    "    \n",
    "    def _build_report(self, test_df):\n",
    "    \n",
    "        def _relation_error_msg(row):\n",
    "            msgs = []\n",
    "            left, right = row['relation']\n",
    "            node_left_type = concept_from(left).title()\n",
    "            node_right_type = concept_from(right).title()\n",
    "            \n",
    "            if int(row['result']) == 2:\n",
    "                return row['details']\n",
    "\n",
    "            if row['details'] is None:\n",
    "                missing = (\n",
    "                    node_right_type \n",
    "                    if concept_attr_from(right) == 'ID' \n",
    "                    else concept_attr_from(right)\n",
    "                )\n",
    "                return (\n",
    "                    f'All {node_left_type} entities are missing {missing}'\n",
    "                )\n",
    "\n",
    "            for node, linked_nodes in row['details']:\n",
    "                msg = f'{node_left_type} {node} is linked to'\n",
    "                if not linked_nodes:\n",
    "                    msg = f'{msg} 0 {node_right_type} entities'\n",
    "                else:\n",
    "                    msg = f'{msg} {len(linked_nodes)} {node_right_type} entities: {linked_nodes}'\n",
    "\n",
    "                msgs.append(msg)\n",
    "\n",
    "            return '\\n'.join(msgs)\n",
    "\n",
    "        def _file_location_msg(row):\n",
    "            if row['error_locations']:\n",
    "                return '\\n'.join(\n",
    "                    f'Found {error_value} in files: {locs}'\n",
    "                    for error_value, locs in row['error_locations']\n",
    "                )\n",
    "            else:\n",
    "                return ''\n",
    "            \n",
    "        report_df = test_df[['result', 'name', 'description', 'details']]\n",
    "        report_df['result'] = test_df['result'].apply(\n",
    "            lambda x: result_to_emoji(x)\n",
    "        )\n",
    "        report_df['details'] = test_df.apply(\n",
    "            lambda row: _relation_error_msg(row),\n",
    "            axis=1\n",
    "        )\n",
    "        report_df['error_locations'] = test_df.apply(\n",
    "            lambda row: _file_location_msg(row),\n",
    "            axis=1\n",
    "        )\n",
    "        return report_df\n",
    "\n",
    "def markdown_report(df):\n",
    "    filepath = os.path.join(os.getcwd(), 'validation_report.md')\n",
    "    \n",
    "    # Prepare data \n",
    "    out_cols = ['result', 'name', 'details', 'error_locations']\n",
    "    counts = (\n",
    "        df[df['test_type'] == 'count-test'][out_cols]\n",
    "        .drop(['error_locations'],axis=1)\n",
    "    )\n",
    "    print(counts.columns)\n",
    "    relations = df[df['test_type'] == 'relationship-test'][out_cols]\n",
    "    attributes = df[df['test_type'] == 'attribute-test'][out_cols]\n",
    "    definitions = df[['test_type', 'name', 'description']]\n",
    "    \n",
    "    # Write markdown     \n",
    "    output = []\n",
    "    output.append('# Validation Report')\n",
    "    output.append('## Count Tests')\n",
    "    output.append(counts.to_markdown(index=False))\n",
    "    output.append('\\n## Relation Tests')\n",
    "    output.append(relations.to_markdown(index=False))\n",
    "    output.append('\\n## Attribute Tests')\n",
    "    output.append(attributes.to_markdown(index=False))\n",
    "    output.append('\\n## Test Definitions')\n",
    "    output.append(definitions.to_markdown(index=False))\n",
    "    \n",
    "    with open(filepath, 'w') as md_file:\n",
    "        md_file.write('\\n'.join(output))\n",
    "    \n",
    "    print(f'\\nGenerated validation report at {filepath}')\n",
    "\n",
    "def run_tests(test_data_dfs, test_params):\n",
    "    report_dfs = []\n",
    "    for test_type, tests in test_params.items():\n",
    "        if test_type == 'count-test':\n",
    "            cls = CountValidationTest\n",
    "        else:\n",
    "            cls = RelationshipValidationTest\n",
    "        \n",
    "        for test in tests:\n",
    "            test_obj = cls(test['name'], test['desc'], *test['params'])\n",
    "            test_df = test_obj.run(test_data_dfs).to_dataframe()\n",
    "            report_df = test_obj.build_report(test_df)            \n",
    "            report_df['test_type'] = test_type\n",
    "            report_dfs.append(report_df)\n",
    "        \n",
    "    report_df = pandas.concat(report_dfs)\n",
    "    report_df = report_df.sort_values(by=['result', 'test_type'])\n",
    "    \n",
    "    markdown_report(report_df)\n",
    "\n",
    "    return report_df\n",
    "\n",
    "test_params = {\n",
    "    'relationship-test': [\n",
    "        {\n",
    "            'name': 'A Participant is in at least 1 Family Group',\n",
    "            'desc': 'Every uniquely identifiable Participant must be linked to at '\n",
    "                    ' least 1 uniquely identifiable Family within the study',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.FAMILY.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Family Group must have at least 1 Participant',\n",
    "            'desc': 'Every uniquely identifiable Family Group must have '\n",
    "                    'at least 1 uniquely identifiable Participant within the study',\n",
    "            'params': (CONCEPT.FAMILY.ID, CONCEPT.PARTICIPANT.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Specimen comes from 1 Participant',\n",
    "            'desc': 'Every uniquely identifiable Specimen must be linked to '\n",
    "                    ' exactly 1 uniquely identifiable Participant within the study',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, CONCEPT.PARTICIPANT.ID, 1, 1)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Participant must have at least 1 Specimen',\n",
    "            'desc': 'Every uniquely identifiable Participant must have at least 1 '\n",
    "                    ' uniquely identifiable Specimen within the study',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.BIOSPECIMEN.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Sequence Manifest File Record represents only 1 Specimen',\n",
    "            'desc': 'Every uniquely identifiable Sequence Manifest File Record must be linked to '\n",
    "                    'exactly 1 uniquely identifiable Specimen within the study',\n",
    "            'params': (CONCEPT.GENOMIC_FILE.URL_LIST, CONCEPT.BIOSPECIMEN.ID, 1, 1)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Specimen must have at least 1 Sequence Manifest File Record',\n",
    "            'desc': 'Every uniquely identifiable specimen must be linked to '\n",
    "                    'at least 1 uniquely identifiable Sequence Manifest File Record '\n",
    "                    'within the study',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, CONCEPT.GENOMIC_FILE.URL_LIST, 1, None)\n",
    "        }\n",
    "    ],\n",
    "    'attribute-test': [\n",
    "        {\n",
    "            'name': 'A Participant must have exactly 1 gender',\n",
    "            'desc': 'Every uniquely identifiable Participant must have exactly 1'\n",
    "                    ' gender from the acceptable list: Male, Female',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.PARTICIPANT.GENDER, 1, 1)\n",
    "        }\n",
    "    ],\n",
    "    'count-test': [\n",
    "        {\n",
    "            'name': 'Expected Participant Unique Count = 10',\n",
    "            'desc': 'The number of uniquely identifiable participants found in '\n",
    "                    'study must be equal to 10',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, 10, 10)\n",
    "        },\n",
    "        {\n",
    "            'name': 'Expected Specimen Unique Count = 12',\n",
    "            'desc': 'The number of uniquely identifiable specimens found in '\n",
    "                    'study must be equal to 12',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, 12, 12)\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "report_df = run_tests(test_data_dfs, test_params)\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
