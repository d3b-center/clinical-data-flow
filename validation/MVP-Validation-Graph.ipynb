{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from pprint import pprint, pformat\n",
    "from itertools import combinations\n",
    "from collections import deque\n",
    "\n",
    "from graph import Graph\n",
    "import networkx as nx\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pandas.options.display.max_colwidth = 0\n",
    "\n",
    "from kf_lib_data_ingest.common.io import (\n",
    "    read_df\n",
    ")\n",
    "from kf_lib_data_ingest.common.concept_schema import (\n",
    "    CONCEPT,\n",
    "    DELIMITER,\n",
    "    concept_from,\n",
    "    concept_attr_from\n",
    ")\n",
    "from kf_lib_data_ingest.common.pandas_utils import merge_wo_duplicates\n",
    "\n",
    "SOURCE_DATA_DIR = os.path.abspath('data')\n",
    "TEST_DATA_DIR = os.path.join(SOURCE_DATA_DIR, 'test')\n",
    "EXTRACT_DATA_DIR = os.path.join('./output/ExtractStage/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     1,
     5,
     27
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted data files ....\n",
      "\n",
      "Test data files ....\n"
     ]
    }
   ],
   "source": [
    "def display_dfs(df_dict):\n",
    "    for key, df in df_dict.items():\n",
    "        print(f'Dataframe {key}')\n",
    "        display(df)\n",
    "        \n",
    "def load_data(input_dir, enable_display=False):\n",
    "    out_dfs = {}\n",
    "    for fn in os.listdir(input_dir):\n",
    "        fp = os.path.join(input_dir, fn)\n",
    "        ext = os.path.splitext(fn)[-1]\n",
    "        if (os.path.isfile(fp) and (not fn.startswith('.')) and (ext not in {'.zip', '.json'})):\n",
    "            out_dfs[fn] = read_df(os.path.join(input_dir, fn))\n",
    "    if enable_display:\n",
    "        print(f'Loading {fn} into df')\n",
    "        display_dfs(out_dfs)\n",
    "\n",
    "    return out_dfs\n",
    "\n",
    "print('\\nExtracted data files ....')\n",
    "# Read in extracted data files into dict\n",
    "extract_data_dfs = load_data(EXTRACT_DATA_DIR)\n",
    "\n",
    "# Test dataframes\n",
    "print('\\nTest data files ....')\n",
    "test_data_dfs = load_data(TEST_DATA_DIR, enable_display=False)\n",
    "\n",
    "# Dev dataframes\n",
    "df_dict = {\n",
    "    'fp.csv': pandas.DataFrame(\n",
    "        {\n",
    "            CONCEPT.FAMILY.ID: ['F1', 'F2', 'F2'],\n",
    "            CONCEPT.PARTICIPANT.ID: ['P1', 'P1' ,'P2']\n",
    "        }\n",
    "    ),\n",
    "    'fpb.csv': pandas.DataFrame(\n",
    "        {\n",
    "            CONCEPT.FAMILY.ID: ['F1', None],\n",
    "            CONCEPT.PARTICIPANT.ID: ['P3', 'P4'],\n",
    "            CONCEPT.BIOSPECIMEN.ID: ['B3', 'B3'],\n",
    "        }\n",
    "    ),\n",
    "    'fb.csv': pandas.DataFrame(\n",
    "        {\n",
    "            CONCEPT.FAMILY.ID: ['F1', 'F1', 'F1'],\n",
    "            CONCEPT.BIOSPECIMEN.ID: ['B1', 'B1', 'B3']\n",
    "        }\n",
    "    ),\n",
    "     'pg.csv': pandas.DataFrame(\n",
    "        {\n",
    "            CONCEPT.PARTICIPANT.ID: ['P1'],\n",
    "            CONCEPT.GENOMIC_FILE.URL_LIST: ['G1'],\n",
    "            CONCEPT.GENOMIC_FILE.CONTROLLED_ACCESS: ['G1']\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     9,
     16,
     23,
     30,
     92,
     107,
     119,
     134,
     142,
     166,
     189,
     204,
     227,
     236,
     237,
     290,
     307,
     318,
     326,
     327,
     341,
     377,
     391,
     394,
     395,
     410,
     417,
     470,
     517,
     549,
     588
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph from 6 files\n",
      "\tAdding edges for ('PARTICIPANT|ID', 'FAMILY|ID')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'PARTICIPANT|ID')\n",
      "\tAdding edges for ('PARTICIPANT|ID', 'FAMILY|ID')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'GENOMIC_FILE|URL_LIST')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'PARTICIPANT|ID')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'PARTICIPANT|ID')\n",
      "\tAdding edges for ('PARTICIPANT|ID', 'FAMILY|ID')\n",
      "\tAdding edges for ('PARTICIPANT|ID', 'GENOMIC_FILE|URL_LIST')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'FAMILY|ID')\n",
      "\tAdding edges for ('BIOSPECIMEN|ID', 'FAMILY|ID')\n",
      "\n",
      "Running PARTICIPANT|ID-->FAMILY|ID test on 6 files ...\n",
      "\n",
      "Running FAMILY|ID-->PARTICIPANT|ID test on 6 files ...\n",
      "\n",
      "Running BIOSPECIMEN|ID-->PARTICIPANT|ID test on 6 files ...\n",
      "\n",
      "Running PARTICIPANT|ID-->BIOSPECIMEN|ID test on 6 files ...\n",
      "\n",
      "Running GENOMIC_FILE|URL_LIST-->BIOSPECIMEN|ID test on 6 files ...\n",
      "\n",
      "Running BIOSPECIMEN|ID-->GENOMIC_FILE|URL_LIST test on 6 files ...\n",
      "\n",
      "Running PARTICIPANT|ID-->PARTICIPANT|GENDER test on 6 files ...\n",
      "\n",
      "Running PARTICIPANT|ID-UNIQUE-COUNT test on 6 files ...\n",
      "\n",
      "Running BIOSPECIMEN|ID-UNIQUE-COUNT test on 6 files ...\n",
      "\n",
      "Generated validation report at /Users/singhn4/Projects/kids_first/kf-ingest-packages/kf_ingest_packages/packages/SD_46SK55A3/validation_report.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>details</th>\n",
       "      <th>error_locations</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅</td>\n",
       "      <td>Expected Participant Unique Count = 10</td>\n",
       "      <td>The number of uniquely identifiable participants found in study must be equal to the expected count</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>count-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅</td>\n",
       "      <td>Expected Specimen Unique Count = 12</td>\n",
       "      <td>The number of uniquely identifiable specimens found in study must be equal to the expected count</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>count-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Participant must have exactly 1 gender</td>\n",
       "      <td>Every uniquely identifiable Participant must have exactly 1 gender from the acceptable list: Male, Female</td>\n",
       "      <td>0 Participant have linked PARTICIPANT|GENDER</td>\n",
       "      <td>None</td>\n",
       "      <td>attribute-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Participant is in at least 1 Family Group</td>\n",
       "      <td>Every uniquely identifiable Participant must be linked to at  least 1 uniquely identifiable Family within the study</td>\n",
       "      <td>Participant P11 is linked to 0 Family entities</td>\n",
       "      <td>Found P11 in files: pf.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Family Group must have at least 1 Participant</td>\n",
       "      <td>Every uniquely identifiable Family Group must have at least 1 uniquely identifiable Participant within the study</td>\n",
       "      <td>Family F12 is linked to 0 Participant entities</td>\n",
       "      <td>Found F12 in files: pf.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Specimen comes from 1 Participant</td>\n",
       "      <td>Every uniquely identifiable Specimen must be linked to  exactly 1 uniquely identifiable Participant within the study</td>\n",
       "      <td>Biospecimen S2 is linked to 2 Participant entities: {'P2', 'P1'}\\nBiospecimen S8 is linked to 0 Participant entities</td>\n",
       "      <td>Found S2 in files: sfp2.csv,spf.csv\\nFound S8 in files: spf.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Participant must have at least 1 Specimen</td>\n",
       "      <td>Every uniquely identifiable Participant must have at least 1  uniquely identifiable Specimen within the study</td>\n",
       "      <td>Participant P11 is linked to 0 Biospecimen entities\\nParticipant P13 is linked to 0 Biospecimen entities</td>\n",
       "      <td>Found P11 in files: pf.csv\\nFound P13 in files: pf.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Sequence Manifest File Record represents only 1 Specimen</td>\n",
       "      <td>Every uniquely identifiable Sequence Manifest File Record must be linked to exactly 1 uniquely identifiable Specimen within the study</td>\n",
       "      <td>Genomic_File ['foo/s5.txt'] is linked to 3 Biospecimen entities: {'S6', 'S5', 'S7'}</td>\n",
       "      <td>Found ['foo/s5.txt'] in files: pg.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>❌</td>\n",
       "      <td>A Specimen must have at least 1 Sequence Manifest File Record</td>\n",
       "      <td>Every uniquely identifiable specimen must be linked to at least 1 uniquely identifiable Sequence Manifest File Record within the study</td>\n",
       "      <td>Biospecimen S2 is linked to 0 Genomic_File entities\\nBiospecimen S1 is linked to 0 Genomic_File entities\\nBiospecimen S3 is linked to 0 Genomic_File entities\\nBiospecimen S4 is linked to 0 Genomic_File entities\\nBiospecimen S8 is linked to 0 Genomic_File entities</td>\n",
       "      <td>Found S2 in files: sfp2.csv,spf.csv\\nFound S1 in files: spf.csv\\nFound S3 in files: spf.csv\\nFound S4 in files: spf.csv\\nFound S8 in files: spf.csv</td>\n",
       "      <td>relationship-test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  result                                                           name  \\\n",
       "0  ✅      Expected Participant Unique Count = 10                          \n",
       "0  ✅      Expected Specimen Unique Count = 12                             \n",
       "0  ❌      A Participant must have exactly 1 gender                        \n",
       "0  ❌      A Participant is in at least 1 Family Group                     \n",
       "0  ❌      A Family Group must have at least 1 Participant                 \n",
       "0  ❌      A Specimen comes from 1 Participant                             \n",
       "0  ❌      A Participant must have at least 1 Specimen                     \n",
       "0  ❌      A Sequence Manifest File Record represents only 1 Specimen      \n",
       "0  ❌      A Specimen must have at least 1 Sequence Manifest File Record   \n",
       "\n",
       "                                                                                                                              description  \\\n",
       "0  The number of uniquely identifiable participants found in study must be equal to the expected count                                      \n",
       "0  The number of uniquely identifiable specimens found in study must be equal to the expected count                                         \n",
       "0  Every uniquely identifiable Participant must have exactly 1 gender from the acceptable list: Male, Female                                \n",
       "0  Every uniquely identifiable Participant must be linked to at  least 1 uniquely identifiable Family within the study                      \n",
       "0  Every uniquely identifiable Family Group must have at least 1 uniquely identifiable Participant within the study                         \n",
       "0  Every uniquely identifiable Specimen must be linked to  exactly 1 uniquely identifiable Participant within the study                     \n",
       "0  Every uniquely identifiable Participant must have at least 1  uniquely identifiable Specimen within the study                            \n",
       "0  Every uniquely identifiable Sequence Manifest File Record must be linked to exactly 1 uniquely identifiable Specimen within the study    \n",
       "0  Every uniquely identifiable specimen must be linked to at least 1 uniquely identifiable Sequence Manifest File Record within the study   \n",
       "\n",
       "                                                                                                                                                                                                                                                                   details  \\\n",
       "0  None                                                                                                                                                                                                                                                                      \n",
       "0  None                                                                                                                                                                                                                                                                      \n",
       "0  0 Participant have linked PARTICIPANT|GENDER                                                                                                                                                                                                                              \n",
       "0  Participant P11 is linked to 0 Family entities                                                                                                                                                                                                                            \n",
       "0  Family F12 is linked to 0 Participant entities                                                                                                                                                                                                                            \n",
       "0  Biospecimen S2 is linked to 2 Participant entities: {'P2', 'P1'}\\nBiospecimen S8 is linked to 0 Participant entities                                                                                                                                                      \n",
       "0  Participant P11 is linked to 0 Biospecimen entities\\nParticipant P13 is linked to 0 Biospecimen entities                                                                                                                                                                  \n",
       "0  Genomic_File ['foo/s5.txt'] is linked to 3 Biospecimen entities: {'S6', 'S5', 'S7'}                                                                                                                                                                                       \n",
       "0  Biospecimen S2 is linked to 0 Genomic_File entities\\nBiospecimen S1 is linked to 0 Genomic_File entities\\nBiospecimen S3 is linked to 0 Genomic_File entities\\nBiospecimen S4 is linked to 0 Genomic_File entities\\nBiospecimen S8 is linked to 0 Genomic_File entities   \n",
       "\n",
       "                                                                                                                                       error_locations  \\\n",
       "0  None                                                                                                                                                  \n",
       "0  None                                                                                                                                                  \n",
       "0  None                                                                                                                                                  \n",
       "0  Found P11 in files: pf.csv                                                                                                                            \n",
       "0  Found F12 in files: pf.csv                                                                                                                            \n",
       "0  Found S2 in files: sfp2.csv,spf.csv\\nFound S8 in files: spf.csv                                                                                       \n",
       "0  Found P11 in files: pf.csv\\nFound P13 in files: pf.csv                                                                                                \n",
       "0  Found ['foo/s5.txt'] in files: pg.csv                                                                                                                 \n",
       "0  Found S2 in files: sfp2.csv,spf.csv\\nFound S1 in files: spf.csv\\nFound S3 in files: spf.csv\\nFound S4 in files: spf.csv\\nFound S8 in files: spf.csv   \n",
       "\n",
       "           test_type  \n",
       "0  count-test         \n",
       "0  count-test         \n",
       "0  attribute-test     \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  \n",
       "0  relationship-test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_relations = {\n",
    "    CONCEPT.FAMILY.ID: {\n",
    "        CONCEPT.PARTICIPANT.ID\n",
    "    },\n",
    "    CONCEPT.PARTICIPANT.ID: {CONCEPT.BIOSPECIMEN.ID},\n",
    "    CONCEPT.BIOSPECIMEN.ID: {CONCEPT.GENOMIC_FILE.URL_LIST},\n",
    "    CONCEPT.GENOMIC_FILE.URL_LIST: {}\n",
    "}\n",
    "\n",
    "def validate_count(count, min_count, max_count):\n",
    "    if count < min_count:\n",
    "        return False\n",
    "    if (max_count is not None) and (count > max_count):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def concept_from(key_or_id):\n",
    "    try:\n",
    "        c = ''.join(key_or_id.split(DELIMITER)[0])\n",
    "    except:\n",
    "        c = None\n",
    "    return c\n",
    "\n",
    "def concept_attr_from(key_or_id):\n",
    "    try:\n",
    "        c = DELIMITER.join(key_or_id.split(DELIMITER)[0:2])\n",
    "    except:\n",
    "        c = None\n",
    "    return c\n",
    "\n",
    "class ExtendedDiGraph(nx.DiGraph):\n",
    "    \"\"\"\n",
    "    Extends graph_theory.Graph with some more functions\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def has_edge(self, left, right, bidirect=True):\n",
    "        return (\n",
    "            super().has_edge(left, right) or\n",
    "            super().has_edge(right, left)\n",
    "        )\n",
    "    \n",
    "    def add_edge(self, left, right, bidirect=True, allow_redundant_path=True): \n",
    "        path_exists = False\n",
    "        # Only add edge if path doesn't already exist between left, right        \n",
    "        if not allow_redundant_path:\n",
    "            try:\n",
    "                path_exists = nx.has_path(self, left, right)\n",
    "            except nx.NodeNotFound:\n",
    "                pass\n",
    "        \n",
    "        if not path_exists:    \n",
    "            super().add_edge(left, right)\n",
    "            if bidirect:\n",
    "                super().add_edge(right, left)\n",
    "        \n",
    "    def parents(self, node_id):\n",
    "        return [edge[0] for edge in self.in_edges(node_id)]\n",
    "    \n",
    "    def children(self, node_id):\n",
    "        return [edge[-1] for edge in self.out_edges(node_id)]\n",
    "    \n",
    "    def debug_view(self):\n",
    "        return {\n",
    "            nid.split(DELIMITER)[-1]: {n.split(DELIMITER)[-1] for n in neighbors}\n",
    "            for nid, neighbors in nx.to_dict_of_dicts(self).items()\n",
    "        }\n",
    "    \n",
    "    def draw(self, output_dir=None, **kwargs):\n",
    "        g = nx.DiGraph(self.debug_view())\n",
    "        pos = nx.spring_layout(g)\n",
    "        plt.figure(1,figsize=(12,12)) \n",
    "        kwargs.update(\n",
    "            {\n",
    "                'font-weight': 'bold',\n",
    "                'with_labels': True,\n",
    "                'node_color': '#33ccff',\n",
    "                'node_size': 400\n",
    "            },\n",
    "        )\n",
    "        nx.draw(g, **kwargs)\n",
    " \n",
    "        output_path = None\n",
    "        if output_dir:\n",
    "            output_path = os.path.join(output_dir, 'graph.svg')\n",
    "            plt.savefig(output_path, format='SVG')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return output_path\n",
    "        \n",
    "class TypeGraph(object):\n",
    "    def __init__(self, relations):\n",
    "        self.adj_list = relations\n",
    "        self.graph = self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        graph = ExtendedDiGraph()\n",
    "        for node, neighbors in self.adj_list.items():\n",
    "            for n in neighbors:\n",
    "                graph.add_edge(node, n)\n",
    "        return graph\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pformat(nx.to_dict_of_dicts(self.graph))\n",
    "    \n",
    "class Node(object):\n",
    "    def __init__(self, key, value, filepaths=None):\n",
    "        self.id = f'{key}{DELIMITER}{value}'\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.filepaths = filepaths\n",
    "        self.concept = concept_from(key)\n",
    "        self.attribute = concept_attr_from(key)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.id\n",
    "    \n",
    "class NodeIndex(object):\n",
    "    def __init__(self):\n",
    "        self.nodes = defaultdict(dict)\n",
    "        \n",
    "    def add_node(self, node):\n",
    "        self.nodes[node.attribute][node.id] = node\n",
    "    \n",
    "    def get_node(self, node_id):\n",
    "        attr = concept_attr_from(node_id)\n",
    "        return self.nodes.get(attr, {}).get(node_id)\n",
    "    \n",
    "    def node_with_same_attr(self, node_id):\n",
    "        attr = concept_attr_from(node_id)\n",
    "        return self.nodes.get(attr, {})    \n",
    "\n",
    "class DataGraph(object):\n",
    "    \n",
    "    def __init__(self, df_dict, type_relations):\n",
    "        self.df_dict = df_dict\n",
    "        self.node_index = NodeIndex()\n",
    "        self.type_graph = TypeGraph(type_relations)\n",
    "        self.build(df_dict)\n",
    "    \n",
    "    def build(self, df_dict):\n",
    "        self.graph = ExtendedDiGraph()\n",
    "        # Build graph of unambiguous connections first\n",
    "        process_later_dfs = {}\n",
    "        print(f'Building graph from {len(df_dict.keys())} files')\n",
    "        for filepath, df in df_dict.items():\n",
    "            process_later = set()\n",
    "            for left, right in combinations(df.columns, 2):\n",
    "                unambiguous_conn = (\n",
    "                    self.type_graph.graph.has_edge(left, right, bidirect=True) \n",
    "                )\n",
    "                if unambiguous_conn:\n",
    "                    self.insert_df(filepath, df[[left, right]])\n",
    "                else:\n",
    "                    process_later.update([left, right])\n",
    "            \n",
    "            df_later = df[list(process_later)]\n",
    "            if not df_later.empty:\n",
    "                process_later_dfs[filepath] = df_later\n",
    "            \n",
    "        # Add ambiguous connections into the graph        \n",
    "        for filepath, df_ in process_later_dfs.items():\n",
    "            self.insert_df(filepath, df_, allow_redundant_path=False)\n",
    "                    \n",
    "    def insert_df(self, filepath, df, allow_redundant_path=False):\n",
    "        ntypes = set(self.type_graph.graph.nodes)\n",
    "        for left, right in combinations(df.columns, 2):\n",
    "            # Only consider columns that are in the type graph             \n",
    "            if (left not in ntypes) or (right not in ntypes):\n",
    "                continue\n",
    "            print(f'\\tAdding edges for {left, right}')\n",
    "            for row in df.to_dict(orient=\"records\"):\n",
    "                # Add left and right nodes of edge\n",
    "                nodes = []\n",
    "                for n in [left, right]:\n",
    "                    if row[n] and pandas.notnull(row[n]):\n",
    "                        node = Node(n, row[n], filepaths=set([filepath]))\n",
    "                        self.add_node(node)\n",
    "                        nodes.append(node)\n",
    "                # Add edges\n",
    "                if len(nodes) > 1: # prevents edges with a node = Null\n",
    "                    self.graph.add_edge(\n",
    "                        nodes[0].id, nodes[1].id, \n",
    "                        bidirect=True, \n",
    "                        allow_redundant_path=allow_redundant_path\n",
    "                    )          \n",
    "                    \n",
    "    def add_node(self, node):\n",
    "        if node.id in self.graph:\n",
    "            filepaths = node.filepaths\n",
    "            node = self.get_node(node.id)\n",
    "            node.filepaths.update(filepaths)\n",
    "\n",
    "        self.graph.add_node(node.id)\n",
    "        self.node_index.add_node(node)\n",
    "    \n",
    "    def get_node(self, node_id):\n",
    "        return self.node_index.get_node(node_id)\n",
    "        \n",
    "    def node_with_same_attr(self, node_id):\n",
    "        return self.node_index.node_with_same_attr(node_id)\n",
    "    \n",
    "    def connected_nodes(self, node_id, concept_attr):\n",
    "        # -- Search the graph of node_id for nodes of same type --\n",
    "        ret_nodes = set()\n",
    "        visited = set([node_id])\n",
    "        queue = deque([node_id])\n",
    "\n",
    "        # BFS\n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "\n",
    "            # Found a node with target concept, add to output\n",
    "            if concept_attr and (concept_attr_from(current) == concept_attr):\n",
    "                ret_nodes.add(current)\n",
    "\n",
    "            # Not found - keep searching neighbors\n",
    "            for neighbor in nx.neighbors(self.graph, current):\n",
    "                # Add neighbor to list if it has not been searched yet\n",
    "                if neighbor not in visited:\n",
    "                    queue.append(neighbor)\n",
    "                    visited.add(neighbor)\n",
    "\n",
    "        return ret_nodes\n",
    "\n",
    "def result_to_emoji(result):\n",
    "    result = int(result)\n",
    "    emap = {\n",
    "        0: '❌',\n",
    "        1: '✅',\n",
    "        2: '☑️'\n",
    "    }\n",
    "    return emap[result]\n",
    "\n",
    "class ValidationTest(ABC):\n",
    "    def __init__(self, name, description, test_type, test_params, id=None):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.test_type = test_type\n",
    "        self.test_params = test_params\n",
    "    \n",
    "    def run(self, df_dict, *args, **kwargs):\n",
    "        print(f'\\nRunning {self.id} test on {len(df_dict.values())} files ...')\n",
    "        return self._run(df_dict, *args, **kwargs)\n",
    "        \n",
    "    def build_report(self, *args, **kwargs):\n",
    "        required_columns = set(['name', 'description', 'result', 'details'])\n",
    "\n",
    "        df = self._build_report(*args, **kwargs)\n",
    "        if not isinstance(df, pandas.DataFrame):\n",
    "            raise Exception(\n",
    "                f'{type(self).__name__}._build_report must return '\n",
    "                f'a pandas.DataFrame object!'\n",
    "            )\n",
    "\n",
    "        if not (required_columns.issubset(set(df.columns))):\n",
    "            raise Exception(\n",
    "                f'{type(self).__name__}._build_report DataFrame must have all required '\n",
    "                f'columns: {required_columns}'\n",
    "            )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _run(self, df_dict):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _build_report(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'test_id': self.id,\n",
    "            'type': self.test_type,\n",
    "            'name': self.name,\n",
    "            'description': self.description,\n",
    "            'input_params': self.test_params\n",
    "        }\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        return pandas.DataFrame([self.to_dict()])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return pformat(self.to_dict())\n",
    "\n",
    "class ValidationTestResult(ABC):\n",
    "    def __init__(\n",
    "        self, validation_test, result, data=None, message=None, result_details=None, error_locations=None\n",
    "    ):\n",
    "        self.id = None\n",
    "        self.validation_test = validation_test\n",
    "        self.result = result\n",
    "        self.data = data\n",
    "        self.message = message or (\n",
    "            f\"{result_to_emoji(int(result))} \"\n",
    "            f\"{self.validation_test.test_type.title()} \"\n",
    "            f\"for '{self.validation_test.name}' \"\n",
    "            f\"{'Succeeded!' if result else 'Failed!'}\"\n",
    "        )\n",
    "        self.result_details = result_details\n",
    "        self.error_locations = error_locations\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = self.validation_test.to_dict()\n",
    "        d.update({\n",
    "            'result': self.result,\n",
    "            'data': self.data,\n",
    "            'message': self.message,\n",
    "            'details': self.result_details,\n",
    "            'error_locations': self.error_locations\n",
    "        })\n",
    "        return d\n",
    "    \n",
    "    def to_dataframe(self):\n",
    "        d = self.to_dict()\n",
    "        df = pandas.DataFrame([d])\n",
    "        return df.drop('data', axis=1)\n",
    "      \n",
    "    def __repr__(self):\n",
    "        return pformat(self.to_dict())\n",
    "        \n",
    "class CountValidationTest(ValidationTest):\n",
    "    def __init__(self, name, description, concept_name, min_count, max_count, data_graph):\n",
    "        super().__init__(\n",
    "            name,\n",
    "            description,\n",
    "            id=f'{concept_name}-UNIQUE-COUNT', \n",
    "            test_type='count-test',\n",
    "            test_params=(concept_name, min_count, max_count)\n",
    "        )\n",
    "        self.concept_name = concept_name\n",
    "        self.min_count = min_count\n",
    "        self.max_count = max_count\n",
    "        self.test_result = None\n",
    "        self.data_graph = data_graph\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = super().to_dict()\n",
    "        d.update(\n",
    "            {\n",
    "                'concept': self.concept_name,\n",
    "                'min_count': self.min_count,\n",
    "                'max_count': self.max_count\n",
    "            }\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "    def _run(self, df_dict):\n",
    "        \n",
    "        # Unique count test\n",
    "        error = None\n",
    "        nodes = self.data_graph.node_with_same_attr(self.concept_name)\n",
    "        uc = len(nodes.keys())\n",
    "        result = validate_count(uc, self.min_count, self.max_count)\n",
    "        # Count check failed\n",
    "        if not result:\n",
    "            error = (self.concept_name, uc)     \n",
    "        self.test_result = ValidationTestResult(self, result, None, result_details=error)\n",
    "        return self.test_result\n",
    "        \n",
    "\n",
    "    def _build_report(self):\n",
    "        test_df = self.test_result.to_dataframe()\n",
    "        report_df = test_df[['result', 'name', 'description', 'details', 'error_locations']]\n",
    "        report_df['result'] = test_df['result'].apply(\n",
    "            lambda x: result_to_emoji(x)\n",
    "        )\n",
    "        report_df['details'] = test_df['details'].apply(\n",
    "            lambda x: f'Found {x[1]} {x[0]} in data' if x else None\n",
    "        )\n",
    "        return report_df\n",
    "\n",
    "class RelationshipValidationTest(ValidationTest):\n",
    "    \"\"\"\n",
    "    Validate relationships between enitity instances\n",
    "\n",
    "    For example given:\n",
    "    \n",
    "        self.node_left=SPECIMEN.ID\n",
    "        self.node_right=PARTICIPANT.ID\n",
    "        self.min_relations=1\n",
    "        self.max_relations =1\n",
    "\n",
    "    A SPECIMEN must be linked to at least 1 PARTICIPANT and no more than 1 PARTICIPANT\n",
    "    Find the SPECIMENS that violate this rule\n",
    "    \"\"\"  \n",
    "    def __init__(\n",
    "        self, name, description, node_left, node_right, min_relations, max_relations, data_graph, \n",
    "        include_implied_conns=True\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name,\n",
    "            description,\n",
    "            id=f'{node_left}-->{node_right}', \n",
    "            test_type='relationship-test',\n",
    "            test_params=(node_left, node_right, min_relations, max_relations)\n",
    "        )\n",
    "        self.node_left = node_left\n",
    "        self.node_right = node_right\n",
    "        self.min_relations = min_relations\n",
    "        self.max_relations = max_relations\n",
    "        self.data_graph = data_graph\n",
    "        self.include_implied_conns=include_implied_conns\n",
    "        self.test_result = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = super().to_dict()\n",
    "        d.update(\n",
    "            {'relation': (self.node_left, self.node_right)}\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "    def _run(self, df_dict):\n",
    "        success = False\n",
    "        all_errors = {}\n",
    "        direct_conn_errors = {}\n",
    "        indirect_conn_errors = {}\n",
    "        for node in self.data_graph.node_with_same_attr(self.node_left):\n",
    "            neighbors = {\n",
    "                n for n in self.data_graph.graph.neighbors(node)\n",
    "                if concept_from(n) == concept_from(self.node_right)\n",
    "            }\n",
    "            success = validate_count(len(neighbors), self.min_relations, self.max_relations)\n",
    "            if not success:\n",
    "                if len(neighbors) == 0:\n",
    "                    indirect_conn_errors[node] = neighbors\n",
    "                else:\n",
    "                    direct_conn_errors[node] = neighbors\n",
    "\n",
    "        if self.include_implied_conns:\n",
    "            nodes = [\n",
    "                node for node, errors in indirect_conn_errors.items()\n",
    "                if not errors\n",
    "            ]\n",
    "            for node in nodes:\n",
    "                indirect_conn_nodes = self.data_graph.connected_nodes(\n",
    "                    node, self.node_right\n",
    "                )\n",
    "                # Found valid connection through indirect links         \n",
    "                success = validate_count(\n",
    "                    len(indirect_conn_nodes), self.min_relations, self.max_relations\n",
    "                )\n",
    "                if success:\n",
    "                    indirect_conn_errors.pop(node)\n",
    "                else:                \n",
    "                    # Node is still invalid due to indirect links\n",
    "                    indirect_conn_errors[node] = indirect_conn_nodes\n",
    "        \n",
    "        # Collect file locations of errors\n",
    "        all_errors.update(direct_conn_errors)\n",
    "        all_errors.update(indirect_conn_errors)\n",
    "        file_locs_of_errors = {\n",
    "            error_node: self.data_graph.get_node(error_node).filepaths\n",
    "            for error_node in all_errors\n",
    "        }\n",
    "        \n",
    "        # Create test result        \n",
    "        self.test_result = ValidationTestResult(\n",
    "            self, \n",
    "            len(all_errors) < 1, \n",
    "            result_details=all_errors,\n",
    "            error_locations=file_locs_of_errors\n",
    "        )\n",
    "        return self.test_result\n",
    "    \n",
    "    def _build_report(self):\n",
    "        def format_errors(row, left, right):\n",
    "            error_dict = row['details']\n",
    "            success = row['result']\n",
    "            if (not success and \n",
    "                (len(error_dict) == len(self.data_graph.node_with_same_attr(self.node_left)) and\n",
    "                all([(len(errors) == 0) for errors in error_dict.values()]))\n",
    "               ):\n",
    "                return f'0 {concept_from(left).title()} have linked {right}'\n",
    "\n",
    "            msgs = []\n",
    "            for node_id, errors in error_dict.items():\n",
    "                n = self.data_graph.get_node(node_id)\n",
    "                concept_right = concept_from(right).title()\n",
    "                if len(errors) > 1:\n",
    "                    e_ids = {self.data_graph.get_node(e_id).value\n",
    "                         for e_id in errors}\n",
    "                    error_str = f'{len(e_ids)} {concept_right} entities: {e_ids}'\n",
    "                else:\n",
    "                    error_str = f'0 {concept_right} entities'\n",
    "                    \n",
    "                msgs.append(f'{concept_from(node_id).title()} {n.value} '\n",
    "                            f'is linked to {error_str}')\n",
    "            return '\\n'.join(msgs)\n",
    "                    \n",
    "        def format_error_locs(loc_dict, left):\n",
    "            if len(self.data_graph.node_with_same_attr(left)) == len(loc_dict):\n",
    "                return None\n",
    "            \n",
    "            msgs = []\n",
    "            for node_id, locations in loc_dict.items():\n",
    "                n = self.data_graph.get_node(node_id)\n",
    "                msgs.append(f\"Found {n.value} in files: {','.join(locations)}\")\n",
    "            return '\\n'.join(msgs)\n",
    "            \n",
    "        test_df = self.test_result.to_dataframe()\n",
    "        report_df = test_df[['result', 'name', 'description', 'details', 'error_locations']]\n",
    "        report_df['result'] = test_df['result'].apply(lambda x: result_to_emoji(x))\n",
    "        report_df['details'] = test_df.apply(\n",
    "            lambda row: format_errors(row, self.node_left, self.node_right), axis=1\n",
    "        )\n",
    "        report_df['error_locations'] = test_df['error_locations'].apply(\n",
    "            lambda x: format_error_locs(x, self.node_left)\n",
    "        )\n",
    "        \n",
    "        return report_df\n",
    "\n",
    "def markdown_report(df, output_dir, graph_img_path=None):\n",
    "    filepath = os.path.join(output_dir, 'validation_report.md')\n",
    "    \n",
    "    # Prepare data \n",
    "    out_cols = ['result', 'name', 'details', 'error_locations']\n",
    "    counts = (\n",
    "        df[df['test_type'] == 'count-test'][out_cols]\n",
    "        .drop(['error_locations'],axis=1)\n",
    "    )\n",
    "    relations = df[df['test_type'] == 'relationship-test'][out_cols]\n",
    "    attributes = df[df['test_type'] == 'attribute-test'][out_cols]\n",
    "    definitions = df[['test_type', 'name', 'description']]\n",
    "    \n",
    "    # Write markdown     \n",
    "    output = []\n",
    "    output.append('# 📓 Data Validation Report')\n",
    "    if graph_img_path:\n",
    "        output.append(f'### \\* View data in a connected [graph]({graph_img_path})')\n",
    "    output.append('## Count Tests')\n",
    "    output.append(counts.to_markdown(index=False))\n",
    "    output.append('\\n## Relation Tests')\n",
    "    output.append(relations.to_markdown(index=False))\n",
    "    output.append('\\n## Attribute Tests')\n",
    "    output.append(attributes.to_markdown(index=False))\n",
    "    output.append('\\n## Test Definitions')\n",
    "    output.append(definitions.to_markdown(index=False))\n",
    "    \n",
    "    with open(filepath, 'w') as md_file:\n",
    "        md_file.write('\\n'.join(output))\n",
    "    \n",
    "    print(f'\\nGenerated validation report at {filepath}')\n",
    "\n",
    "def run_tests(df_dict, test_params, type_relations, draw_graph=False):\n",
    "    report_dfs = []\n",
    "    \n",
    "    # Build data graph\n",
    "    g = DataGraph(df_dict, type_relations)\n",
    "    \n",
    "    # Run tests\n",
    "    for test_type, tests in test_params.items():\n",
    "        if test_type == 'count-test':\n",
    "            cls = CountValidationTest\n",
    "            extra_params = (g,)\n",
    "        else:\n",
    "            cls = RelationshipValidationTest\n",
    "            extra_params = (g,)\n",
    "            \n",
    "        for test in tests:\n",
    "            test_obj = cls(\n",
    "                test['name'], test['desc'], *test['params'], \n",
    "                *extra_params, **test.get('kwargs', {})\n",
    "            )\n",
    "            test_df = test_obj.run(df_dict).to_dataframe()\n",
    "            report_df = test_obj.build_report()\n",
    "            report_df['test_type'] = test_type\n",
    "            report_dfs.append(report_df)\n",
    "    \n",
    "    # Collect test report dfs     \n",
    "    report_df = pandas.concat(report_dfs)\n",
    "    report_df = report_df.sort_values(by=['result', 'test_type'])\n",
    "\n",
    "    # Draw graph\n",
    "    p = None\n",
    "    if draw_graph:\n",
    "        p = g.graph.draw(output_dir=os.getcwd())\n",
    "\n",
    "    # Create markdown report\n",
    "    markdown_report(report_df, output_dir=os.getcwd(), graph_img_path=p)\n",
    "\n",
    "    return report_df\n",
    "\n",
    "test_params = {\n",
    "    'relationship-test': [\n",
    "        {\n",
    "            'name': 'A Participant is in at least 1 Family Group',\n",
    "            'desc': 'Every uniquely identifiable Participant must be linked to at '\n",
    "                    ' least 1 uniquely identifiable Family within the study',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.FAMILY.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Family Group must have at least 1 Participant',\n",
    "            'desc': 'Every uniquely identifiable Family Group must have '\n",
    "                    'at least 1 uniquely identifiable Participant within the study',\n",
    "            'params': (CONCEPT.FAMILY.ID, CONCEPT.PARTICIPANT.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Specimen comes from 1 Participant',\n",
    "            'desc': 'Every uniquely identifiable Specimen must be linked to '\n",
    "                    ' exactly 1 uniquely identifiable Participant within the study',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, CONCEPT.PARTICIPANT.ID, 1, 1)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Participant must have at least 1 Specimen',\n",
    "            'desc': 'Every uniquely identifiable Participant must have at least 1 '\n",
    "                    ' uniquely identifiable Specimen within the study',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.BIOSPECIMEN.ID, 1, None)\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Sequence Manifest File Record represents only 1 Specimen',\n",
    "            'desc': 'Every uniquely identifiable Sequence Manifest File Record must be linked to '\n",
    "                    'exactly 1 uniquely identifiable Specimen within the study',\n",
    "            'params': (CONCEPT.GENOMIC_FILE.URL_LIST, CONCEPT.BIOSPECIMEN.ID, 1, 1),\n",
    "        },\n",
    "        {\n",
    "            'name': 'A Specimen must have at least 1 Sequence Manifest File Record',\n",
    "            'desc': 'Every uniquely identifiable specimen must be linked to '\n",
    "                    'at least 1 uniquely identifiable Sequence Manifest File Record '\n",
    "                    'within the study',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, CONCEPT.GENOMIC_FILE.URL_LIST, 1, None)\n",
    "        }\n",
    "    ],\n",
    "    'attribute-test': [\n",
    "        {\n",
    "            'name': 'A Participant must have exactly 1 gender',\n",
    "            'desc': 'Every uniquely identifiable Participant must have exactly 1'\n",
    "                    ' gender from the acceptable list: Male, Female',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, CONCEPT.PARTICIPANT.GENDER, 1, 1)\n",
    "        }\n",
    "    ],\n",
    "    'count-test': [\n",
    "        {\n",
    "            'name': 'Expected Participant Unique Count = 10',\n",
    "            'desc': 'The number of uniquely identifiable participants found in '\n",
    "                    'study must be equal to the expected count',\n",
    "            'params': (CONCEPT.PARTICIPANT.ID, 10, 10)\n",
    "        },\n",
    "        {\n",
    "            'name': 'Expected Specimen Unique Count = 12',\n",
    "            'desc': 'The number of uniquely identifiable specimens found in '\n",
    "                    'study must be equal to the expected count',\n",
    "            'params': (CONCEPT.BIOSPECIMEN.ID, 12, 12)\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "report_df = run_tests(test_data_dfs, test_params, type_relations)\n",
    "display(report_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
